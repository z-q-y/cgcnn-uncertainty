{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/z/zulissi/.conda/envs/cgcnn/lib/python3.6/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated since IPython 4.0. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/global/homes/z/zulissi/.conda/envs/cgcnn/lib/python3.6/site-packages/ipycache.py:17: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils.traitlets import Unicode\n"
     ]
    }
   ],
   "source": [
    "%load_ext ipycache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document demonstrates the making, training, saving, loading, and usage of a sklearn-compliant CGCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cgcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset as mongo docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import tqdm\n",
    "import multiprocess as mp\n",
    "\n",
    "#Load a selection of documents\n",
    "docs = pickle.load(open('/global/homes/z/zulissi/CO_docs.pkl','rb'))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currently we add connectivity change as another metric of reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mongo\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.analysis.structure_analyzer import VoronoiConnectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved variables 'docs' to file '/global/u2/z/zulissi/software/cgcnn_sklearn/CO_docs_connectivity.pkl'.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20833it [18:10, 19.11it/s]\n"
     ]
    }
   ],
   "source": [
    "%%cache CO_docs_connectivity.pkl docs\n",
    "\n",
    "def doc_to_connectivity_array(doc):\n",
    "    #pymatgen-style connectivity discarding atoms w/ tags=1 (adsorbates)\n",
    "    \n",
    "    #Remove the adsorbate\n",
    "    atoms = mongo.make_atoms_from_doc(doc)\n",
    "    atoms = atoms[atoms.get_tags()==0]\n",
    "    \n",
    "    #turn to crystal, get the connectivity matrix\n",
    "    crystal = AseAtomsAdaptor.get_structure(atoms)\n",
    "    VC = VoronoiConnectivity(crystal)\n",
    "\n",
    "    #Find the max connection to each other atom (regardless of which image)\n",
    "    connectivity_array = np.max(VC.connectivity_array,2)\n",
    "  \n",
    "    return connectivity_array\n",
    "\n",
    "def max_connectivity_change(doc):\n",
    "    \n",
    "    #Get the connectivity of the initial and final image\n",
    "    array_final = doc_to_connectivity_array(doc)\n",
    "    array_initial = doc_to_connectivity_array(doc['initial_configuration'])\n",
    "\n",
    "    #Return the maximum change in the connectivity array \n",
    "    return np.max(np.abs(array_final-array_initial))\n",
    "\n",
    "#Add the connectivity change score to the documents\n",
    "with mp.Pool(16) as pool:\n",
    "    scores = list(tqdm.tqdm(pool.imap(max_connectivity_change,docs,chunksize=40)))\n",
    "    \n",
    "for doc,score in zip(docs,scores):\n",
    "    doc['movement_data']['max_connectivity_change']=score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the size of the features from the data transformer, to be used in setting up the net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved variables 'SDT_list_distance_relaxed' to file '/global/u2/z/zulissi/software/cgcnn_sklearn/SDT_list_distance_relaxed.pkl'.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 20833/20833 [33:47<00:00, 10.28it/s]\n"
     ]
    }
   ],
   "source": [
    "%%cache SDT_list_distance_relaxed.pkl SDT_list_distance_relaxed\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mongo\n",
    "from cgcnn.data import StructureData, ListDataset, StructureDataTransformer\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "SDT = StructureDataTransformer(atom_init_loc='atom_init.json',\n",
    "                              max_num_nbr=12,\n",
    "                              step=0.2,\n",
    "                              radius=1,\n",
    "                              use_tag=False,\n",
    "                              use_fixed_info=False,\n",
    "                              use_distance=True)\n",
    "\n",
    "\n",
    "import multiprocess as mp\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "SDT_out = SDT.transform(docs)\n",
    "\n",
    "with mp.Pool(16) as pool:\n",
    "    SDT_list_distance_relaxed = list(tqdm.tqdm(pool.imap(lambda x: SDT_out[x],range(len(SDT_out)),chunksize=40),total=len(SDT_out)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved variables 'SDT_list_distance_unrelaxed' to file '/global/u2/z/zulissi/software/cgcnn_sklearn/SDT_list_distance_unrelaxed.pkl'.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 20833/20833 [35:59<00:00,  9.65it/s]\n"
     ]
    }
   ],
   "source": [
    "%%cache SDT_list_distance_unrelaxed.pkl SDT_list_distance_unrelaxed\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mongo\n",
    "from cgcnn.data import StructureData, ListDataset, StructureDataTransformer\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SDT = StructureDataTransformer(atom_init_loc='atom_init.json',\n",
    "                              max_num_nbr=12,\n",
    "                              step=0.2,\n",
    "                              radius=1,\n",
    "                              use_tag=True,\n",
    "                              use_fixed_info=False,\n",
    "                              use_distance=True)\n",
    "\n",
    "\n",
    "import multiprocess as mp\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "SDT_out = SDT.transform(docs)\n",
    "\n",
    "with mp.Pool(16) as pool:\n",
    "    SDT_list_distance_unrelaxed = list(tqdm.tqdm(pool.imap(lambda x: SDT_out[x],range(len(SDT_out)),chunksize=40),total=len(SDT_out)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cgcnn]",
   "language": "python",
   "name": "conda-env-cgcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
