{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zulissi/miniconda3/envs/cgcnn/lib/python3.6/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated since IPython 4.0. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/home/zulissi/miniconda3/envs/cgcnn/lib/python3.6/site-packages/ipycache.py:17: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils.traitlets import Unicode\n"
     ]
    }
   ],
   "source": [
    "%load_ext ipycache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/zulissi/software/adamwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document demonstrates the making, training, saving, loading, and usage of a sklearn-compliant CGCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cgcnn\n",
    "import pickle\n",
    "\n",
    "#Select which GPU to use if necessary\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset as mongo docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_all_unfiltered = pickle.load(open('CO_docs_connectivity.pkl','rb'))['docs_all']\n",
    "SDT_list_distance_relaxed= pickle.load(open('SDT_list_distance_relaxed.pkl','rb'))['SDT_list_distance_relaxed']\n",
    "SDT_list_distance_unrelaxed= pickle.load(open('SDT_list_distance_unrelaxed.pkl','rb'))['SDT_list_distance_unrelaxed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_all_unfiltered, SDT_list_distance_relaxed, SDT_list_distance_unrelaxed = zip(*[[doc,SDTR, SDTU] for doc,SDTR, SDTU in \n",
    "                                                                         zip(docs_all_unfiltered, SDT_list_distance_relaxed, SDT_list_distance_unrelaxed) \n",
    "                                        if -3<doc['energy']<1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the target list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SS = StandardScaler()\n",
    "SS.fit(np.array([doc['energy'] for doc in docs_all_unfiltered]).reshape(-1,1))\n",
    "target_list = SS.transform(np.array([doc['energy'] for doc in docs_all_unfiltered]).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGCNN model with skorch to make it sklearn compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from skorch.callbacks import Checkpoint, LoadInitState #needs skorch 0.4.0, conda-forge version at 0.3.0 doesn't cut it\n",
    "from cgcnn.data import collate_pool\n",
    "from skorch import NeuralNetRegressor\n",
    "from cgcnn.model import CrystalGraphConvNet\n",
    "import torch\n",
    "from cgcnn.data import MergeDataset\n",
    "import skorch.callbacks.base\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best',fn_prefix='valid_best_')\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('valid_best_params.pt')\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from skorch.dataset import CVSplit\n",
    "from skorch.callbacks.lr_scheduler import WarmRestartLR, LRScheduler\n",
    "from adamw import AdamW\n",
    "from cosine_scheduler import CosineLRWithRestarts\n",
    "\n",
    "def compare_relaxed_unrelaxed(targets, docs_all, SDT_list_relaxed, SDT_list_unrelaxed, filter_to_use, fname, test_split=0.05, valid_split=0.05):\n",
    "    \n",
    "    SDT_training_relaxed_train, SDT_training_relaxed_test, \\\n",
    "    SDT_training_unrelaxed_train, SDT_training_unrelaxed_test, \\\n",
    "    target_training, target_test = train_test_split([a for a,b in zip(SDT_list_distance_relaxed, filter_to_use) if b],\n",
    "                                                    [a for a,b in zip(SDT_list_distance_unrelaxed, filter_to_use) if b],\n",
    "                                                    target_list[filter_to_use], \n",
    "                                                    test_size=valid_split, \n",
    "                                                    random_state=42)\n",
    "\n",
    "    #Set the size of the features from the SDT object\n",
    "    targets = target_training\n",
    "    SDT_list = SDT_training_relaxed_train\n",
    "    structures = SDT_list[0]\n",
    "    orig_atom_fea_len = structures[0].shape[-1]\n",
    "    nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "    #Specify the internal train/test split\n",
    "    train_test_splitter = ShuffleSplit(test_size=test_split, random_state=42)\n",
    "\n",
    "    # warm restart scheduling from https://arxiv.org/pdf/1711.05101.pdf\n",
    "    split = next(train_test_splitter.split(SDT_training_relaxed_train))\n",
    "    LR_schedule = LRScheduler(CosineLRWithRestarts, batch_size=214, epoch_size=len(SDT_training_relaxed_train), restart_period=10, t_mult=1.2)\n",
    "\n",
    "    net_relaxed = NeuralNetRegressor(\n",
    "        CrystalGraphConvNet,\n",
    "        module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "        module__nbr_fea_len = nbr_fea_len,\n",
    "        batch_size=214,\n",
    "        module__classification=False,\n",
    "        lr=0.0056,\n",
    "        max_epochs=100,\n",
    "        module__atom_fea_len=46,\n",
    "        module__h_fea_len=83,\n",
    "        module__n_conv=8,\n",
    "        module__n_h=4,\n",
    "        optimizer__weight_decay=1e-5,\n",
    "        optimizer=AdamW, # from https://arxiv.org/pdf/1711.05101.pdf\n",
    "        iterator_train__pin_memory=True,\n",
    "        iterator_train__num_workers=0,\n",
    "        iterator_train__collate_fn = collate_pool,\n",
    "        iterator_valid__pin_memory=True,\n",
    "        iterator_valid__num_workers=0,\n",
    "        iterator_valid__collate_fn = collate_pool,\n",
    "        device=device,\n",
    "        criterion=torch.nn.MSELoss,\n",
    "        dataset=MergeDataset,\n",
    "        train_split = CVSplit(cv=train_test_splitter),\n",
    "        callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    "    )\n",
    "\n",
    "    #Fit the relaxed model\n",
    "    net_relaxed.initialize()\n",
    "    net_relaxed.fit(SDT_training_relaxed_train,target_training)\n",
    "\n",
    "    #Get the train/test split used during the training\n",
    "    train_indices, valid_indices = next(train_test_splitter.split(SDT_training_relaxed_train))\n",
    "\n",
    "    #Use the fitted model to predict the values\n",
    "    training_data = {'actual_value':SS.inverse_transform(np.array(target_training.reshape(-1))[train_indices]),\n",
    "                     'predicted_value':SS.inverse_transform(net_relaxed.predict(SDT_training_relaxed_train)[train_indices].reshape(-1))}\n",
    "    test_data ={'actual_value':SS.inverse_transform(np.array(target_test).reshape(-1)),\n",
    "                'predicted_value':SS.inverse_transform(net_relaxed.predict(SDT_training_relaxed_test).reshape(-1))}\n",
    "    validation_data = {'actual_value':SS.inverse_transform(np.array(target_training.reshape(-1))[valid_indices]),\n",
    "                     'predicted_value':SS.inverse_transform(net_relaxed.predict(SDT_training_relaxed_train)[valid_indices].reshape(-1))}\n",
    "\n",
    "    df_training = pd.DataFrame(training_data)\n",
    "    df_validation = pd.DataFrame(validation_data)\n",
    "    df_test = pd.DataFrame(test_data)\n",
    "\n",
    "    #Plot the parity plot for the train/test/valid splits\n",
    "    f, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.scatter(df_training['actual_value'], df_training['predicted_value'], color='orange', \n",
    "               marker='o', alpha=0.5, label='train\\nMAE=%0.2f, RMSE=%0.2f, R$^2$=%0.2f'\\\n",
    "                %(mean_absolute_error(df_training['actual_value'], df_training['predicted_value']), \n",
    "                  np.sqrt(mean_squared_error(df_training['actual_value'], df_training['predicted_value'])),\n",
    "                  r2_score(df_training['actual_value'], df_training['predicted_value'])))\n",
    "\n",
    "    ax.scatter(df_validation['actual_value'], df_validation['predicted_value'], color='blue', \n",
    "               marker='o', alpha=0.5, label='valid\\nMAE=%0.2f, RMSE=%0.2f, R$^2$=%0.2f'\\\n",
    "                %(mean_absolute_error(df_validation['actual_value'], df_validation['predicted_value']), \n",
    "                  np.sqrt(mean_squared_error(df_validation['actual_value'], df_validation['predicted_value'])),\n",
    "                  r2_score(df_validation['actual_value'], df_validation['predicted_value'])))\n",
    "\n",
    "    ax.scatter(df_test['actual_value'], df_test['predicted_value'], color='green', \n",
    "               marker='o', alpha=0.5, label='test\\nMAE=%0.2f, RMSE=%0.2f, R$^2$=%0.2f'\\\n",
    "                %(mean_absolute_error(df_test['actual_value'], df_test['predicted_value']), \n",
    "                  np.sqrt(mean_squared_error(df_test['actual_value'], df_test['predicted_value'])),\n",
    "                  r2_score(df_test['actual_value'], df_test['predicted_value'])))\n",
    "\n",
    "\n",
    "    ax.plot([min(df_training['actual_value']), max(df_training['actual_value'])], \n",
    "            [min(df_training['actual_value']), max(df_training['actual_value'])], 'k--')\n",
    "\n",
    "    # format graph\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.set_xlabel('DFT E (eV)', fontsize=14)\n",
    "    ax.set_ylabel('CGCNN predicted E (eV)', fontsize=14)\n",
    "    ax.set_title('Relaxed', fontsize=14) \n",
    "    ax.legend(fontsize=12)\n",
    "    plt.savefig('graphs/%s_parity_relaxed.pdf'%fname)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    #Specify the feature sizes for the relaxed object\n",
    "    targets = target_training\n",
    "    SDT_list = SDT_training_unrelaxed_train\n",
    "    structures = SDT_list[0]\n",
    "    orig_atom_fea_len = structures[0].shape[-1]\n",
    "    nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "    #Specify the internal train/test split strategy\n",
    "    train_test_splitter = ShuffleSplit(test_size=test_split, random_state=42)\n",
    "\n",
    "    # warm restart scheduling from https://arxiv.org/pdf/1711.05101.pdf\n",
    "    split = next(train_test_splitter.split(SDT_training_unrelaxed_train))\n",
    "    LR_schedule = LRScheduler(CosineLRWithRestarts, batch_size=214, epoch_size=len(SDT_training_unrelaxed_train), restart_period=10, t_mult=1.2)\n",
    "\n",
    "    net_unrelaxed = NeuralNetRegressor(\n",
    "        CrystalGraphConvNet,\n",
    "        module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "        module__nbr_fea_len = nbr_fea_len,\n",
    "        batch_size=214,\n",
    "        module__classification=False,\n",
    "        lr=0.0056,\n",
    "        max_epochs=150, #should be 170 \n",
    "        module__atom_fea_len=46,\n",
    "        module__h_fea_len=83,\n",
    "        module__n_conv=8,\n",
    "        module__n_h=4,\n",
    "        optimizer__weight_decay=1e-5,\n",
    "        optimizer=AdamW, # from https://arxiv.org/pdf/1711.05101.pdf\n",
    "        iterator_train__pin_memory=True,\n",
    "        iterator_train__num_workers=0,\n",
    "        iterator_train__collate_fn = collate_pool,\n",
    "        iterator_valid__pin_memory=True,\n",
    "        iterator_valid__num_workers=0,\n",
    "        iterator_valid__collate_fn = collate_pool,\n",
    "        device=device,\n",
    "        criterion=torch.nn.L1Loss,\n",
    "        dataset=MergeDataset,\n",
    "        train_split = CVSplit(cv=train_test_splitter),\n",
    "        callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    "    )\n",
    "\n",
    "    #Fit the unrelaxed cgcnn model\n",
    "    net_unrelaxed.initialize()\n",
    "    net_unrelaxed.fit(SDT_training_unrelaxed_train,target_training)\n",
    "\n",
    "    train_indices, valid_indices = next(train_test_splitter.split(SDT_training_unrelaxed_train))\n",
    "\n",
    "    training_data = {'actual_value':SS.inverse_transform(np.array(target_training.reshape(-1))[train_indices]),\n",
    "                     'predicted_value':SS.inverse_transform(net_unrelaxed.predict(SDT_training_unrelaxed_train)[train_indices].reshape(-1))}\n",
    "    test_data ={'actual_value':SS.inverse_transform(np.array(target_test).reshape(-1)),\n",
    "                'predicted_value':SS.inverse_transform(net_unrelaxed.predict(SDT_training_unrelaxed_test).reshape(-1))}\n",
    "    validation_data = {'actual_value':SS.inverse_transform(np.array(target_training.reshape(-1))[valid_indices]),\n",
    "                     'predicted_value':SS.inverse_transform(net_unrelaxed.predict(SDT_training_unrelaxed_train)[valid_indices].reshape(-1))}\n",
    "\n",
    "    df_training = pd.DataFrame(training_data)\n",
    "    df_validation = pd.DataFrame(validation_data)\n",
    "    df_test = pd.DataFrame(test_data)\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.scatter(df_training['actual_value'], df_training['predicted_value'], color='orange', \n",
    "               marker='o', alpha=0.5, label='train\\nMAE=%0.2f, RMSE=%0.2f, R$^2$=%0.2f'\\\n",
    "                %(mean_absolute_error(df_training['actual_value'], df_training['predicted_value']), \n",
    "                  np.sqrt(mean_squared_error(df_training['actual_value'], df_training['predicted_value'])),\n",
    "                  r2_score(df_training['actual_value'], df_training['predicted_value'])))\n",
    "\n",
    "    ax.scatter(df_validation['actual_value'], df_validation['predicted_value'], color='blue', \n",
    "               marker='o', alpha=0.5, label='valid\\nMAE=%0.2f, RMSE=%0.2f, R$^2$=%0.2f'\\\n",
    "                %(mean_absolute_error(df_validation['actual_value'], df_validation['predicted_value']), \n",
    "                  np.sqrt(mean_squared_error(df_validation['actual_value'], df_validation['predicted_value'])),\n",
    "                  r2_score(df_validation['actual_value'], df_validation['predicted_value'])))\n",
    "\n",
    "    ax.scatter(df_test['actual_value'], df_test['predicted_value'], color='green', \n",
    "               marker='o', alpha=0.5, label='test\\nMAE=%0.2f, RMSE=%0.2f, R$^2$=%0.2f'\\\n",
    "                %(mean_absolute_error(df_test['actual_value'], df_test['predicted_value']), \n",
    "                  np.sqrt(mean_squared_error(df_test['actual_value'], df_test['predicted_value'])),\n",
    "                  r2_score(df_test['actual_value'], df_test['predicted_value'])))\n",
    "\n",
    "\n",
    "    ax.plot([min(df_training['actual_value']), max(df_training['actual_value'])], \n",
    "            [min(df_training['actual_value']), max(df_training['actual_value'])], 'k--')\n",
    "\n",
    "    # format graph\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.set_xlabel('DFT E (eV)', fontsize=14)\n",
    "    ax.set_ylabel('CGCNN predicted E (eV)', fontsize=14)\n",
    "    ax.set_title('Unrelaxed', fontsize=14) \n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "    plt.savefig('graphs/%s_parity_unrelaxed.pdf'%fname)\n",
    "    plt.show()\n",
    "    \n",
    "    relaxed_energies = SS.inverse_transform(net_relaxed.predict(SDT_list_distance_relaxed).reshape((-1)))\n",
    "    unrelaxed_energies = SS.inverse_transform(net_unrelaxed.predict(SDT_list_distance_unrelaxed).reshape((-1)))\n",
    "\n",
    "\n",
    "    #Generate a dataframe (one per input document) with the relaxed/unrelaxed data and other metrics\n",
    "    df = pd.DataFrame({'relaxed_energies':relaxed_energies.reshape((-1)),\n",
    "                       'unrelaxed_energies':unrelaxed_energies.reshape((-1)),\n",
    "                       'index':range(len(docs_all)),\n",
    "                       'residual':np.abs(relaxed_energies-unrelaxed_energies).reshape((-1)),\n",
    "                        'max_connectivity_change':[doc['movement_data']['max_connectivity_change'] for doc in docs_all],\n",
    "                       'max_surface_movement':[doc['movement_data']['max_surface_movement'] for doc in docs_all],\n",
    "                        'adsorbate_movement':[doc['movement_data']['max_adsorbate_movement'] for doc in docs_all],\n",
    "                        'bare_slab_movement':[doc['movement_data']['max_bare_slab_movement'] for doc in docs_all],\n",
    "                       'fmax':[doc['results']['fmax'] for doc in docs_all],\n",
    "                       'energy':[doc['results']['energy'] for doc in docs_all],\n",
    "                       'mongo_id':[doc['mongo_id'] for doc in docs_all]})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-adf439351bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                               \u001b[0mSDT_list_distance_unrelaxed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                               \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                               'first_filter')\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m df_filter = data_frame_first['residual']<3*np.std(data_frame_first['relaxed_energies']-\n",
      "\u001b[0;32m<ipython-input-8-6188407ea810>\u001b[0m in \u001b[0;36mcompare_relaxed_unrelaxed\u001b[0;34m(targets, docs_all, SDT_list_relaxed, SDT_list_unrelaxed, filter_to_use, fname, test_split, valid_split)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#Fit the relaxed model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mnet_relaxed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mnet_relaxed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDT_training_relaxed_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgcnn/lib/python3.6/site-packages/skorch/net.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgcnn/lib/python3.6/site-packages/skorch/net.py\u001b[0m in \u001b[0;36minitialize_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/cgcnn_sklearn/cgcnn/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, orig_atom_fea_len, nbr_fea_len, atom_fea_len, n_conv, h_fea_len, n_h, classification)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m            \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgcnn/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgcnn/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgcnn/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgcnn/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "data_frame_first = compare_relaxed_unrelaxed(target_list, \n",
    "                                              docs_all_unfiltered, \n",
    "                                              SDT_list_distance_relaxed, \n",
    "                                              SDT_list_distance_unrelaxed, \n",
    "                                              [True]*len(target_list),\n",
    "                                              'first_filter')\n",
    "\n",
    "df_filter = data_frame_first['residual']<3*np.std(data_frame_first['relaxed_energies']-\n",
    "                                                  data_frame_first['unrelaxed_energies'])\n",
    "\n",
    "\n",
    "data_frame_second = compare_relaxed_unrelaxed(target_list, \n",
    "                                              docs_all_unfiltered, \n",
    "                                              SDT_list_distance_relaxed, \n",
    "                                              SDT_list_distance_unrelaxed, \n",
    "                                              df_filter.values,\n",
    "                                              'second_filter')\n",
    "\n",
    "df_filter = (data_frame_first['residual']<3*np.std(data_frame_first['relaxed_energies']-\n",
    "                                                   data_frame_first['unrelaxed_energies']))& \\\n",
    "            (data_frame_second['residual']<3*np.std(data_frame_second['relaxed_energies']-\n",
    "                                                    data_frame_second['unrelaxed_energies']))\n",
    "\n",
    "    \n",
    "#Fit the final model after two filter steps\n",
    "data_frame_final = compare_relaxed_unrelaxed(target_list, \n",
    "                                              docs_all_unfiltered, \n",
    "                                              SDT_list_distance_relaxed, \n",
    "                                              SDT_list_distance_unrelaxed, \n",
    "                                              df_filter,\n",
    "                                              'final_model',\n",
    "                                             test_split=0.2,valid_split=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
