{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document demonstrates the making, training, saving, loading, and usage of a sklearn-compliant CGCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset of docs taken from jupyter-dev using:\n",
    "#     from gaspy import gasdb, defaults\n",
    "#     import warnings\n",
    "#     warnings.filterwarnings('ignore')\n",
    "\n",
    "#     filters = defaults.adsorption_filters('CO')\n",
    "#     #filters['results.energy'] = {'$gt': -3.5, '$lt': 9.0}\n",
    "#     #filters['processed_data.movement_data.max_adsorbate_movement']['$lt'] = 4.0 #specifically for OOH vs OH\n",
    "\n",
    "#     # Establish the fingerprints that are needed for the preprocessing\n",
    "#     fingerprints = {}\n",
    "#     fingerprints['atoms']='$atoms'\n",
    "#     fingerprints['results']='$results'\n",
    "#     fingerprints['max_surface_movement']='$processed_data.movement_data.max_surface_movement'\n",
    "#     fingerprints['adsorption_site'] = '$initial_configuration.atoms.atoms'\n",
    "#     # Pull the documents and then modify them so that they'll work with the preprocessor\n",
    "#     docs = gasdb.get_adsorption_docs(['CO'],extra_fingerprints=fingerprints, filters=filters)\n",
    "\n",
    "#CO_docs = pickle.load(open('/home/zulissi/CO_docs_200.pkl','rb'))\n",
    "    \n",
    "\n",
    "# with open('/home/zulissi/CO_docs_200.pkl','wb') as fhandle:\n",
    "#     pickle.dump(CO_docs,fhandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset as mongo docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "docs = pickle.load(open('/home/zulissi/CO_docs.pkl','rb'))\n",
    "random.shuffle(sdocs)\n",
    "docs = docs[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the size of the features from the data transformer, to be used in setting up the net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mongo\n",
    "from cgcnn.data import StructureData, ListDataset, StructureDataTransformer\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "energies = np.array([doc['energy'] for doc in docs])\n",
    "scaler = StandardScaler().fit(energies.reshape(-1, 1))\n",
    "\n",
    "\n",
    "SDT = StructureDataTransformer(atom_init_loc='/home/zulissi/software/cgcnn_sklearn/atom_init.json',\n",
    "                              max_num_nbr=7,\n",
    "                              radius=1,\n",
    "                              use_tag=True,\n",
    "                              use_fixed_info=True)\n",
    "\n",
    "SDT_out = SDT.transform(docs)\n",
    "\n",
    "structures = SDT_out[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGCNN model with skorch to make it sklearn compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from skorch.callbacks import Checkpoint, LoadInitState #needs skorch 0.4.0, conda-forge version at 0.3.0 doesn't cut it\n",
    "from cgcnn.data import collate_pool\n",
    "from skorch import NeuralNetRegressor\n",
    "from cgcnn.model import CrystalGraphConvNet\n",
    "import torch\n",
    "from cgcnn.data import MergeDataset\n",
    "import skorch.callbacks.base\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best')\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('params.pt')\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n",
    "net = NeuralNetRegressor(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "    module__nbr_fea_len = nbr_fea_len,\n",
    "    module__atom_fea_len=46,\n",
    "    module__h_fea_len=83,\n",
    "    module__n_conv=8,\n",
    "    module__n_h=4,\n",
    "    iterator_train__batch_size=214,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__collate_fn = collate_pool,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn = collate_pool,\n",
    "    max_epochs=10,\n",
    "    lr=np.exp(-5.18),\n",
    "    optimizer=Adam,    \n",
    "    device=device,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    callbacks=[cp, load_best_valid_loss]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example converting all the documents up front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:40<00:00,  9.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocess as mp\n",
    "\n",
    "SDT_out = SDT.transform(docs)\n",
    "\n",
    "with mp.Pool(4) as pool:\n",
    "    SDT_list = list(tqdm.tqdm(pool.imap(lambda x: SDT_out[x],range(len(SDT_out)),chunksize=40),total=len(SDT_out)))\n",
    "\n",
    "#Make the target list\n",
    "target_list = scaler.transform(np.array([doc['energy'] for doc in docs]).reshape(-1,1))\n",
    "target_list = np.array([doc['energy'] for doc in docs]).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test single training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8001\u001b[0m        \u001b[32m0.5471\u001b[0m     +  1.3488\n",
      "      2        \u001b[36m0.5914\u001b[0m        0.5832        0.8138\n",
      "      3        \u001b[36m0.5816\u001b[0m        \u001b[32m0.5184\u001b[0m     +  0.8133\n",
      "      4        \u001b[36m0.5577\u001b[0m        \u001b[32m0.4731\u001b[0m     +  0.8122\n",
      "      5        \u001b[36m0.4889\u001b[0m        \u001b[32m0.4160\u001b[0m     +  0.8125\n",
      "      6        \u001b[36m0.4307\u001b[0m        0.6140        0.8127\n",
      "      7        \u001b[36m0.4185\u001b[0m        0.8031        0.8117\n",
      "      8        \u001b[36m0.4011\u001b[0m        0.6072        0.8123\n",
      "      9        \u001b[36m0.4009\u001b[0m        0.4360        0.8120\n",
      "     10        \u001b[36m0.3819\u001b[0m        0.4194        0.8129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=CrystalGraphConvNet(\n",
       "    (embedding): Linear(in_features=94, out_features=46, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (5): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (6): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (7): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "    )\n",
       "    (conv_to_fc): Linear(in_features=46, out_features=83, bias=True)\n",
       "    (conv_to_fc_softplus): Softplus(beta=1, threshold=20)\n",
       "    (fcs): ModuleList(\n",
       "      (0): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (1): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (2): Linear(in_features=83, out_features=83, bias=True)\n",
       "    )\n",
       "    (softpluses): ModuleList(\n",
       "      (0): Softplus(beta=1, threshold=20)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "      (2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (fc_out): Linear(in_features=83, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the NN\n",
    "net.fit(SDT_list,target_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test saving and loading and using a pipeline (single-threaded conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(SDT,net)\n",
    "\n",
    "#Save the fitted sklearn-compatible pipeline\n",
    "with open('fitted-pipeline.pkl','wb') as fhandle:\n",
    "    pickle.dump(pipe,fhandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8384002 ],\n",
       "       [ 0.44950756],\n",
       "       [ 0.8624066 ],\n",
       "       [-1.0550358 ],\n",
       "       [ 0.98745465],\n",
       "       [ 0.586292  ],\n",
       "       [ 0.95263827],\n",
       "       [ 0.98174685],\n",
       "       [-0.05879573],\n",
       "       [ 0.800063  ],\n",
       "       [ 0.9196766 ],\n",
       "       [-0.32130083],\n",
       "       [ 0.48017555],\n",
       "       [ 0.94949406],\n",
       "       [ 0.5370213 ],\n",
       "       [-0.55270046],\n",
       "       [-0.4050538 ],\n",
       "       [ 0.504645  ],\n",
       "       [-0.9592412 ],\n",
       "       [-0.20463465],\n",
       "       [ 0.72949976],\n",
       "       [-0.99070495],\n",
       "       [ 0.7621159 ],\n",
       "       [ 0.7684037 ],\n",
       "       [ 0.7612388 ],\n",
       "       [ 0.22055197],\n",
       "       [-1.2068889 ],\n",
       "       [ 0.9720404 ],\n",
       "       [ 0.6367614 ],\n",
       "       [ 0.8578729 ],\n",
       "       [-1.1057863 ],\n",
       "       [-0.94082546],\n",
       "       [ 0.81635696],\n",
       "       [-1.0139832 ],\n",
       "       [-0.87557876],\n",
       "       [-0.7303076 ],\n",
       "       [ 0.9046748 ],\n",
       "       [ 0.9248668 ],\n",
       "       [ 0.79441607],\n",
       "       [-1.1301421 ],\n",
       "       [-0.03730621],\n",
       "       [ 0.58609164],\n",
       "       [ 0.94179046],\n",
       "       [-0.77236825],\n",
       "       [ 0.85958314],\n",
       "       [ 0.48410448],\n",
       "       [ 0.63400453],\n",
       "       [-1.029718  ],\n",
       "       [ 0.9004668 ],\n",
       "       [ 0.7214897 ],\n",
       "       [ 0.9843204 ],\n",
       "       [-0.61086833],\n",
       "       [ 0.793079  ],\n",
       "       [-0.3711305 ],\n",
       "       [ 0.8422901 ],\n",
       "       [ 0.86950356],\n",
       "       [ 0.5396488 ],\n",
       "       [ 0.44992936],\n",
       "       [ 0.69516873],\n",
       "       [ 0.8583404 ],\n",
       "       [-1.1302599 ],\n",
       "       [ 0.80368596],\n",
       "       [ 0.090514  ],\n",
       "       [ 0.81615216],\n",
       "       [-0.762279  ],\n",
       "       [-1.1559085 ],\n",
       "       [-0.27358642],\n",
       "       [ 0.7404951 ],\n",
       "       [-0.31927398],\n",
       "       [-1.292768  ],\n",
       "       [-0.07947829],\n",
       "       [ 0.8286565 ],\n",
       "       [-1.0579424 ],\n",
       "       [ 0.53049314],\n",
       "       [-0.78159565],\n",
       "       [-0.51592076],\n",
       "       [ 0.8482907 ],\n",
       "       [ 0.40187606],\n",
       "       [ 0.97363067],\n",
       "       [ 0.31011257],\n",
       "       [ 0.66099554],\n",
       "       [ 0.6254129 ],\n",
       "       [-1.0976151 ],\n",
       "       [ 0.7900842 ],\n",
       "       [ 0.7362409 ],\n",
       "       [ 0.8059936 ],\n",
       "       [ 0.61698985],\n",
       "       [ 0.64963496],\n",
       "       [ 0.6139987 ],\n",
       "       [ 0.07716371],\n",
       "       [-1.0266927 ],\n",
       "       [-0.25024912],\n",
       "       [ 0.9991309 ],\n",
       "       [ 0.98545283],\n",
       "       [ 0.023541  ],\n",
       "       [ 0.09130891],\n",
       "       [ 0.8602811 ],\n",
       "       [ 0.8998933 ],\n",
       "       [ 0.6905578 ],\n",
       "       [ 0.77461964],\n",
       "       [ 0.81542104],\n",
       "       [ 0.91447514],\n",
       "       [ 0.7037238 ],\n",
       "       [ 0.5465103 ],\n",
       "       [ 0.78530383],\n",
       "       [ 0.80119085],\n",
       "       [ 0.90251136],\n",
       "       [ 0.57608324],\n",
       "       [-0.32529458],\n",
       "       [-0.14004184],\n",
       "       [ 0.21290071],\n",
       "       [ 0.76766855],\n",
       "       [ 0.7233908 ],\n",
       "       [ 0.72723746],\n",
       "       [ 0.5046366 ],\n",
       "       [-0.25942594],\n",
       "       [ 0.6408396 ],\n",
       "       [ 0.9038222 ],\n",
       "       [-0.02790239],\n",
       "       [ 0.73767763],\n",
       "       [-0.6177504 ],\n",
       "       [ 0.5095489 ],\n",
       "       [ 0.91437215],\n",
       "       [-0.8823241 ],\n",
       "       [ 0.59309584],\n",
       "       [ 0.78506225],\n",
       "       [ 1.069926  ],\n",
       "       [ 0.6882246 ],\n",
       "       [ 0.5940194 ],\n",
       "       [-1.1003015 ],\n",
       "       [ 0.46003103],\n",
       "       [-0.91583776],\n",
       "       [ 0.8306576 ],\n",
       "       [ 0.8143902 ],\n",
       "       [ 0.18597215],\n",
       "       [ 0.20556962],\n",
       "       [-0.5827766 ],\n",
       "       [ 0.7541151 ],\n",
       "       [ 1.0685568 ],\n",
       "       [ 0.16983438],\n",
       "       [ 0.5077293 ],\n",
       "       [ 0.78607327],\n",
       "       [-0.42739543],\n",
       "       [-0.45682013],\n",
       "       [-0.9448456 ],\n",
       "       [ 0.7525747 ],\n",
       "       [-0.78878665],\n",
       "       [-0.90708303],\n",
       "       [ 0.7498382 ],\n",
       "       [ 0.90009797],\n",
       "       [ 0.5532867 ],\n",
       "       [ 1.0105671 ],\n",
       "       [ 0.8658537 ],\n",
       "       [-1.0326877 ],\n",
       "       [ 0.8859576 ],\n",
       "       [-0.30616963],\n",
       "       [-0.04425036],\n",
       "       [ 0.92567086],\n",
       "       [ 0.7179732 ],\n",
       "       [ 0.87624353],\n",
       "       [ 0.7182766 ],\n",
       "       [ 0.8593958 ],\n",
       "       [ 0.64202744],\n",
       "       [ 0.462164  ],\n",
       "       [ 0.6002448 ],\n",
       "       [-0.11299181],\n",
       "       [ 0.6121494 ],\n",
       "       [-0.64373684],\n",
       "       [-0.15781231],\n",
       "       [-0.9163403 ],\n",
       "       [ 0.8282485 ],\n",
       "       [ 0.47387153],\n",
       "       [-0.50488657],\n",
       "       [ 0.64467084],\n",
       "       [-0.7019267 ],\n",
       "       [ 0.8071647 ],\n",
       "       [ 0.50677305],\n",
       "       [-0.61572   ],\n",
       "       [-1.0606672 ],\n",
       "       [-0.4421193 ],\n",
       "       [ 0.89394003],\n",
       "       [-0.01170371],\n",
       "       [ 0.1586537 ],\n",
       "       [ 0.9092242 ],\n",
       "       [ 0.72463673],\n",
       "       [ 0.63619316],\n",
       "       [ 0.991762  ],\n",
       "       [ 0.05907911],\n",
       "       [-0.9637608 ],\n",
       "       [ 0.89903384],\n",
       "       [-0.9229325 ],\n",
       "       [-1.143086  ],\n",
       "       [ 0.7215676 ],\n",
       "       [ 0.45729792],\n",
       "       [-0.6699875 ],\n",
       "       [-0.18044405],\n",
       "       [-1.1022238 ],\n",
       "       [ 0.60721666],\n",
       "       [ 0.5371308 ],\n",
       "       [ 0.9755165 ],\n",
       "       [ 0.6334204 ],\n",
       "       [-0.8482137 ],\n",
       "       [ 0.76816595],\n",
       "       [-0.47025084],\n",
       "       [ 0.8054909 ],\n",
       "       [ 0.62661886],\n",
       "       [ 0.807602  ],\n",
       "       [ 0.901126  ],\n",
       "       [-0.9815822 ],\n",
       "       [ 0.4579304 ],\n",
       "       [ 0.60102814],\n",
       "       [-0.5848319 ],\n",
       "       [ 0.7741697 ],\n",
       "       [-0.71746147],\n",
       "       [ 0.04325635],\n",
       "       [-1.0064793 ],\n",
       "       [-0.6749192 ],\n",
       "       [-0.35965547],\n",
       "       [ 0.737019  ],\n",
       "       [-0.75093895],\n",
       "       [ 0.6273938 ],\n",
       "       [ 0.8870111 ],\n",
       "       [ 0.51717687],\n",
       "       [ 0.84937596],\n",
       "       [ 0.792458  ],\n",
       "       [ 0.75468034],\n",
       "       [ 1.0129881 ],\n",
       "       [-0.6101226 ],\n",
       "       [-0.58535093],\n",
       "       [-0.669576  ],\n",
       "       [ 0.46310556],\n",
       "       [-0.99957377],\n",
       "       [ 0.7921586 ],\n",
       "       [ 0.7871118 ],\n",
       "       [-0.6362038 ],\n",
       "       [ 0.7669449 ],\n",
       "       [ 0.78025866],\n",
       "       [-0.5098268 ],\n",
       "       [ 0.22577551],\n",
       "       [ 0.7696623 ],\n",
       "       [-1.10365   ],\n",
       "       [-0.8853559 ],\n",
       "       [ 0.28843257],\n",
       "       [ 0.6092798 ],\n",
       "       [ 1.0373093 ],\n",
       "       [ 0.6404911 ],\n",
       "       [ 0.7451038 ],\n",
       "       [ 0.54854053],\n",
       "       [ 0.39654118],\n",
       "       [-0.5500592 ],\n",
       "       [ 0.2294698 ],\n",
       "       [ 0.54631364],\n",
       "       [-0.9995952 ],\n",
       "       [ 0.91072273],\n",
       "       [ 0.524003  ],\n",
       "       [ 0.18832415],\n",
       "       [ 0.3214243 ],\n",
       "       [ 0.6039951 ],\n",
       "       [ 0.76178527],\n",
       "       [-0.27102163],\n",
       "       [-0.4930899 ],\n",
       "       [ 0.57184595],\n",
       "       [ 0.55692637],\n",
       "       [ 0.815616  ],\n",
       "       [ 0.19354688],\n",
       "       [ 0.7660431 ],\n",
       "       [-0.94719255],\n",
       "       [ 0.91467893],\n",
       "       [ 0.8392372 ],\n",
       "       [ 0.72652656],\n",
       "       [-0.11707227],\n",
       "       [-0.80670786],\n",
       "       [ 0.5697707 ],\n",
       "       [ 0.64721495],\n",
       "       [ 0.7895668 ],\n",
       "       [ 0.7211127 ],\n",
       "       [ 0.7515224 ],\n",
       "       [ 0.6469452 ],\n",
       "       [ 0.51973504],\n",
       "       [ 0.08287161],\n",
       "       [ 0.621355  ],\n",
       "       [ 0.71484846],\n",
       "       [ 0.60544527],\n",
       "       [-0.80012226],\n",
       "       [ 0.40610203],\n",
       "       [ 0.6176029 ],\n",
       "       [ 0.6721327 ],\n",
       "       [ 0.30743238],\n",
       "       [ 0.9913778 ],\n",
       "       [ 0.9414039 ],\n",
       "       [ 0.867892  ],\n",
       "       [ 0.79244596],\n",
       "       [ 0.7405791 ],\n",
       "       [-0.95433563],\n",
       "       [ 0.5789632 ],\n",
       "       [-0.85180527],\n",
       "       [ 1.0484858 ],\n",
       "       [ 0.49711025],\n",
       "       [-0.8812707 ],\n",
       "       [-0.91217524],\n",
       "       [ 0.8857027 ],\n",
       "       [ 0.7258967 ],\n",
       "       [ 0.7679105 ],\n",
       "       [ 0.8196914 ],\n",
       "       [-0.20302482],\n",
       "       [-0.42075482],\n",
       "       [ 0.5485331 ],\n",
       "       [ 0.80877525],\n",
       "       [-0.5892924 ],\n",
       "       [ 0.99643785],\n",
       "       [-0.7871486 ],\n",
       "       [ 0.8708403 ],\n",
       "       [-0.03177388],\n",
       "       [ 0.881326  ],\n",
       "       [-0.45762926],\n",
       "       [ 0.9629869 ],\n",
       "       [-0.9796168 ],\n",
       "       [ 0.8581111 ],\n",
       "       [-0.10425885],\n",
       "       [-0.24225822],\n",
       "       [ 0.7675509 ],\n",
       "       [ 0.76466584],\n",
       "       [ 0.46383435],\n",
       "       [-0.8575477 ],\n",
       "       [-0.12369773],\n",
       "       [ 0.03677507],\n",
       "       [-0.95122665],\n",
       "       [ 0.72714657],\n",
       "       [ 0.7456938 ],\n",
       "       [ 0.48524702],\n",
       "       [ 0.84249645],\n",
       "       [-0.8139595 ],\n",
       "       [-0.16970955],\n",
       "       [ 0.76223797],\n",
       "       [ 0.9321856 ],\n",
       "       [ 0.96672446],\n",
       "       [ 0.67643225],\n",
       "       [ 0.7061201 ],\n",
       "       [-0.7360055 ],\n",
       "       [ 0.6645279 ],\n",
       "       [-0.97101575],\n",
       "       [ 0.7043312 ],\n",
       "       [-0.56597286],\n",
       "       [ 0.77463543],\n",
       "       [-0.45343468],\n",
       "       [ 0.9895731 ],\n",
       "       [ 0.97225744],\n",
       "       [ 0.5734494 ],\n",
       "       [-0.96519667],\n",
       "       [-0.6839553 ],\n",
       "       [-0.96105474],\n",
       "       [ 0.67366886],\n",
       "       [ 0.57914954],\n",
       "       [ 0.14174508],\n",
       "       [ 1.0513939 ],\n",
       "       [ 0.58560437],\n",
       "       [ 0.46971387],\n",
       "       [ 0.49874738],\n",
       "       [ 0.88308614],\n",
       "       [-0.9011339 ],\n",
       "       [ 0.88678485],\n",
       "       [-0.7317877 ],\n",
       "       [-0.51556206],\n",
       "       [ 0.8420447 ],\n",
       "       [ 0.7257102 ],\n",
       "       [-0.6536544 ],\n",
       "       [-0.9690272 ],\n",
       "       [ 0.8789715 ],\n",
       "       [-0.81490463],\n",
       "       [ 0.46538064],\n",
       "       [-0.95615673],\n",
       "       [ 0.7466707 ],\n",
       "       [-0.653181  ],\n",
       "       [ 0.16047211],\n",
       "       [ 0.49143058],\n",
       "       [-0.34493715],\n",
       "       [ 1.0003874 ],\n",
       "       [-0.60032743],\n",
       "       [ 0.9909771 ],\n",
       "       [ 0.54735506],\n",
       "       [ 0.9329957 ],\n",
       "       [ 0.80400825],\n",
       "       [ 0.7409044 ],\n",
       "       [-0.7903755 ],\n",
       "       [ 0.42952567],\n",
       "       [ 0.8465586 ],\n",
       "       [ 0.548793  ],\n",
       "       [ 0.5600474 ],\n",
       "       [ 0.4523386 ],\n",
       "       [-1.0254104 ],\n",
       "       [ 0.86955255],\n",
       "       [-0.9436507 ],\n",
       "       [ 0.5019615 ],\n",
       "       [ 0.9318417 ],\n",
       "       [-0.2841628 ],\n",
       "       [-0.28231293],\n",
       "       [ 0.6186766 ],\n",
       "       [ 0.6031355 ],\n",
       "       [-1.0220512 ],\n",
       "       [ 0.8165065 ],\n",
       "       [ 0.60919946],\n",
       "       [-0.16398114],\n",
       "       [ 0.44695747],\n",
       "       [ 0.9081051 ],\n",
       "       [-0.7593141 ],\n",
       "       [-0.5156939 ],\n",
       "       [ 0.8834433 ],\n",
       "       [-0.42859563],\n",
       "       [ 0.07098252],\n",
       "       [ 0.4924307 ],\n",
       "       [ 0.8785229 ],\n",
       "       [ 0.9335106 ],\n",
       "       [ 0.52045774],\n",
       "       [ 0.51883435],\n",
       "       [ 1.0013624 ],\n",
       "       [ 0.93845737],\n",
       "       [ 0.87812   ],\n",
       "       [-0.979718  ],\n",
       "       [ 0.62481105],\n",
       "       [ 0.6448597 ],\n",
       "       [-0.8783175 ],\n",
       "       [-0.7462822 ],\n",
       "       [-0.49374276],\n",
       "       [-0.68242663],\n",
       "       [-0.4110521 ],\n",
       "       [-0.46709198],\n",
       "       [-0.5554667 ],\n",
       "       [-0.27178547],\n",
       "       [ 0.9574303 ],\n",
       "       [-1.0120914 ],\n",
       "       [-0.34484464],\n",
       "       [-0.66216093],\n",
       "       [ 0.70460176],\n",
       "       [ 0.61764425],\n",
       "       [-0.25530335],\n",
       "       [-0.50947815],\n",
       "       [ 0.57962406],\n",
       "       [ 0.68875444],\n",
       "       [-0.87220544],\n",
       "       [ 0.5090834 ],\n",
       "       [-1.0033315 ],\n",
       "       [ 0.7674515 ],\n",
       "       [ 0.6564165 ],\n",
       "       [-0.8759031 ],\n",
       "       [ 0.9676084 ],\n",
       "       [ 0.921108  ],\n",
       "       [-0.6943143 ],\n",
       "       [ 1.0311862 ],\n",
       "       [-0.8673608 ],\n",
       "       [ 0.5947777 ],\n",
       "       [ 0.34108964],\n",
       "       [-0.24531737],\n",
       "       [ 0.94649005],\n",
       "       [ 0.7560759 ],\n",
       "       [ 0.8584447 ],\n",
       "       [-0.13526712],\n",
       "       [-0.9248208 ],\n",
       "       [ 0.8473014 ],\n",
       "       [ 0.25661233],\n",
       "       [ 0.98195475],\n",
       "       [ 0.7544608 ],\n",
       "       [ 0.55096495],\n",
       "       [ 1.0085377 ],\n",
       "       [-0.6339833 ],\n",
       "       [ 0.8405449 ],\n",
       "       [-0.98726314],\n",
       "       [-0.36414218],\n",
       "       [ 0.86379015],\n",
       "       [-1.015176  ],\n",
       "       [ 0.6716499 ],\n",
       "       [-0.40815508],\n",
       "       [-0.4484095 ],\n",
       "       [ 0.76398677],\n",
       "       [ 0.6840466 ],\n",
       "       [ 0.88869774],\n",
       "       [ 0.5447603 ],\n",
       "       [ 0.24813873],\n",
       "       [-0.18251468],\n",
       "       [ 0.8378945 ],\n",
       "       [ 0.5307472 ],\n",
       "       [-0.85318255],\n",
       "       [ 0.88365096],\n",
       "       [ 0.52272725],\n",
       "       [ 0.26393145],\n",
       "       [ 0.35515627],\n",
       "       [-0.37565693],\n",
       "       [ 0.81338173],\n",
       "       [-0.05102375],\n",
       "       [ 0.58995384],\n",
       "       [ 0.672488  ],\n",
       "       [ 0.8095086 ],\n",
       "       [-0.04177501],\n",
       "       [ 0.9444672 ],\n",
       "       [-0.72899085],\n",
       "       [ 0.8655372 ],\n",
       "       [-1.1696998 ],\n",
       "       [-0.11905542],\n",
       "       [-0.96267253],\n",
       "       [ 0.87128896],\n",
       "       [ 0.5654039 ],\n",
       "       [ 0.8229143 ],\n",
       "       [ 0.5677885 ],\n",
       "       [ 0.45037034],\n",
       "       [ 0.8635373 ],\n",
       "       [-0.8971301 ],\n",
       "       [-1.2255664 ],\n",
       "       [ 0.30540624],\n",
       "       [ 0.90508235],\n",
       "       [ 0.9163753 ],\n",
       "       [ 0.46549323],\n",
       "       [ 0.5427003 ],\n",
       "       [-0.6694254 ],\n",
       "       [-0.6561286 ],\n",
       "       [ 0.7850136 ],\n",
       "       [ 0.19443516],\n",
       "       [-1.0826696 ],\n",
       "       [ 0.63425106],\n",
       "       [-0.14910212],\n",
       "       [-0.522224  ],\n",
       "       [-0.97649425],\n",
       "       [ 0.8258226 ],\n",
       "       [ 0.5709783 ],\n",
       "       [ 0.7701916 ],\n",
       "       [-0.6921737 ],\n",
       "       [ 0.55156636],\n",
       "       [ 0.5823215 ],\n",
       "       [ 0.9224505 ],\n",
       "       [ 0.4600114 ],\n",
       "       [-0.8083796 ],\n",
       "       [-1.0074091 ],\n",
       "       [ 0.75015277],\n",
       "       [ 0.5416163 ],\n",
       "       [ 0.575487  ],\n",
       "       [ 0.5292707 ],\n",
       "       [ 0.49904788],\n",
       "       [-0.4928044 ],\n",
       "       [ 0.8168418 ],\n",
       "       [ 0.8767487 ],\n",
       "       [-0.7758966 ],\n",
       "       [ 0.16772577],\n",
       "       [ 0.04982727],\n",
       "       [-1.0431317 ],\n",
       "       [ 0.7354659 ],\n",
       "       [ 0.83280015],\n",
       "       [ 0.6208461 ],\n",
       "       [-0.9050115 ],\n",
       "       [ 0.12274806],\n",
       "       [-0.68165326],\n",
       "       [ 0.5905422 ],\n",
       "       [ 0.85705435],\n",
       "       [ 0.35003617],\n",
       "       [ 0.5578209 ],\n",
       "       [ 0.6981953 ],\n",
       "       [ 0.4707073 ],\n",
       "       [ 0.6596562 ],\n",
       "       [ 0.90011525],\n",
       "       [ 0.87985736],\n",
       "       [ 0.90257126],\n",
       "       [ 0.6933362 ],\n",
       "       [ 0.57900083],\n",
       "       [ 0.7866967 ],\n",
       "       [ 0.51911545],\n",
       "       [-0.15565805],\n",
       "       [ 0.7795749 ],\n",
       "       [-0.77294505],\n",
       "       [-1.0668669 ],\n",
       "       [ 0.344863  ],\n",
       "       [ 0.5729063 ],\n",
       "       [ 0.44847822],\n",
       "       [ 0.73457575],\n",
       "       [-1.0563658 ],\n",
       "       [ 0.29546577],\n",
       "       [ 0.6999538 ],\n",
       "       [ 0.8344042 ],\n",
       "       [ 0.33488864],\n",
       "       [ 0.19685802],\n",
       "       [-0.24643499],\n",
       "       [ 0.78049654],\n",
       "       [ 0.79420775],\n",
       "       [ 0.61196226],\n",
       "       [-0.494276  ],\n",
       "       [ 0.6198442 ],\n",
       "       [ 0.35222074],\n",
       "       [ 0.512358  ],\n",
       "       [ 0.8781845 ],\n",
       "       [ 0.5243155 ],\n",
       "       [ 0.55288583],\n",
       "       [ 0.6277279 ],\n",
       "       [-0.8398572 ],\n",
       "       [ 0.8975795 ],\n",
       "       [-0.36058426],\n",
       "       [ 0.3892437 ],\n",
       "       [-0.61384946],\n",
       "       [ 0.30554214],\n",
       "       [ 0.8043599 ],\n",
       "       [-1.1119232 ],\n",
       "       [ 0.9809448 ],\n",
       "       [ 0.70714647],\n",
       "       [ 0.90793437],\n",
       "       [ 0.58739626],\n",
       "       [-1.0960702 ],\n",
       "       [-0.5465901 ],\n",
       "       [ 0.46375686],\n",
       "       [-0.29695764],\n",
       "       [ 0.8024643 ],\n",
       "       [-1.0278969 ],\n",
       "       [ 0.5819981 ],\n",
       "       [ 0.91183573],\n",
       "       [ 0.8318125 ],\n",
       "       [-0.42962173],\n",
       "       [ 0.20730814],\n",
       "       [ 0.74951917],\n",
       "       [ 0.72666466],\n",
       "       [ 0.6558214 ],\n",
       "       [ 0.80486953],\n",
       "       [ 0.46792802],\n",
       "       [ 0.832406  ],\n",
       "       [ 0.83666456],\n",
       "       [-0.22097132],\n",
       "       [-0.53599894],\n",
       "       [ 0.83868945],\n",
       "       [-0.38993818],\n",
       "       [ 0.42583382],\n",
       "       [ 0.7548327 ],\n",
       "       [ 0.49684656],\n",
       "       [ 0.6262786 ],\n",
       "       [ 0.18090318],\n",
       "       [ 0.7896626 ],\n",
       "       [ 0.6835742 ],\n",
       "       [ 0.81661135],\n",
       "       [ 0.01252558],\n",
       "       [-0.76759243],\n",
       "       [ 0.648733  ],\n",
       "       [ 1.015611  ],\n",
       "       [ 0.55457544],\n",
       "       [ 0.8856808 ],\n",
       "       [ 0.8750507 ],\n",
       "       [ 0.7901139 ],\n",
       "       [-0.5027038 ],\n",
       "       [ 1.0927885 ],\n",
       "       [ 0.5343548 ],\n",
       "       [-0.7379157 ],\n",
       "       [ 0.7735388 ],\n",
       "       [-0.9589943 ],\n",
       "       [-0.46335185],\n",
       "       [-0.99706334],\n",
       "       [-0.00504956],\n",
       "       [ 0.08876166],\n",
       "       [-0.00702836],\n",
       "       [-0.24041855],\n",
       "       [ 0.80035156],\n",
       "       [ 0.5725396 ],\n",
       "       [ 0.64715946],\n",
       "       [ 0.79755837],\n",
       "       [-1.1991187 ],\n",
       "       [-0.6788854 ],\n",
       "       [ 0.5151385 ],\n",
       "       [ 0.6607857 ],\n",
       "       [ 0.5595388 ],\n",
       "       [ 0.5967926 ],\n",
       "       [ 0.53909045],\n",
       "       [-0.86961913],\n",
       "       [ 1.0263064 ],\n",
       "       [ 0.5804297 ],\n",
       "       [ 0.71771765],\n",
       "       [-0.7810824 ],\n",
       "       [-0.00154693],\n",
       "       [ 0.57041913],\n",
       "       [ 0.5683346 ],\n",
       "       [ 0.21243054],\n",
       "       [-0.8845629 ],\n",
       "       [-0.5562361 ],\n",
       "       [-0.14200914],\n",
       "       [-1.1811454 ],\n",
       "       [ 0.48005572],\n",
       "       [ 0.75235707],\n",
       "       [ 0.82752496],\n",
       "       [ 0.63388413],\n",
       "       [ 0.01585299],\n",
       "       [ 0.7817158 ],\n",
       "       [-0.81066257],\n",
       "       [ 0.35399225],\n",
       "       [-0.8310384 ],\n",
       "       [ 0.95495397],\n",
       "       [ 0.817712  ],\n",
       "       [ 0.53038263],\n",
       "       [ 0.5981188 ],\n",
       "       [-0.2327235 ],\n",
       "       [ 0.83598644],\n",
       "       [-1.0898399 ],\n",
       "       [ 0.3918043 ],\n",
       "       [ 0.05882982],\n",
       "       [-1.1217085 ],\n",
       "       [ 0.87911135],\n",
       "       [ 0.763815  ],\n",
       "       [ 0.80601305],\n",
       "       [ 0.5359004 ],\n",
       "       [ 0.0657683 ],\n",
       "       [-0.28767014],\n",
       "       [ 0.44433308],\n",
       "       [-0.8534069 ],\n",
       "       [ 0.746913  ],\n",
       "       [ 0.65054435],\n",
       "       [-0.74953693],\n",
       "       [-0.10417189],\n",
       "       [ 0.71419907],\n",
       "       [ 0.31416994],\n",
       "       [ 0.6359782 ],\n",
       "       [ 0.7128233 ],\n",
       "       [-0.27726704],\n",
       "       [ 0.67011863],\n",
       "       [ 0.63763857],\n",
       "       [ 0.52232134],\n",
       "       [ 1.049481  ],\n",
       "       [ 0.36862904],\n",
       "       [ 0.36805964],\n",
       "       [ 0.91467613],\n",
       "       [-0.2170498 ],\n",
       "       [ 0.68637884],\n",
       "       [-0.25882992],\n",
       "       [-0.4720965 ],\n",
       "       [ 0.67974055],\n",
       "       [-0.3888692 ],\n",
       "       [ 0.9498794 ],\n",
       "       [ 0.9356674 ],\n",
       "       [ 0.5549823 ],\n",
       "       [ 0.23573586],\n",
       "       [ 0.53839415],\n",
       "       [ 0.84458685],\n",
       "       [ 0.55206615],\n",
       "       [ 0.89915955],\n",
       "       [-0.27534175],\n",
       "       [-0.8846207 ],\n",
       "       [ 0.5835386 ],\n",
       "       [-0.6849194 ],\n",
       "       [ 0.79647636],\n",
       "       [-0.3509231 ],\n",
       "       [-0.6059111 ],\n",
       "       [ 0.5792842 ],\n",
       "       [-0.6188288 ],\n",
       "       [ 0.5093308 ],\n",
       "       [-0.92370784],\n",
       "       [ 0.50614995],\n",
       "       [-0.98096377],\n",
       "       [ 0.32692492],\n",
       "       [-0.89622885],\n",
       "       [ 0.7755407 ],\n",
       "       [-0.38402167],\n",
       "       [ 0.99669945],\n",
       "       [ 0.773037  ],\n",
       "       [ 0.9584429 ],\n",
       "       [ 0.8549277 ],\n",
       "       [-0.9231072 ],\n",
       "       [ 0.546724  ],\n",
       "       [ 0.9016451 ],\n",
       "       [-1.0521203 ],\n",
       "       [ 0.25850368],\n",
       "       [ 0.85159   ],\n",
       "       [ 0.89910626],\n",
       "       [-0.34631428],\n",
       "       [-0.16484578],\n",
       "       [-0.23848978],\n",
       "       [-1.0379735 ],\n",
       "       [-1.1810377 ],\n",
       "       [ 0.85433465],\n",
       "       [ 0.191986  ],\n",
       "       [-0.15682763],\n",
       "       [ 0.20915142],\n",
       "       [ 0.71848947],\n",
       "       [-0.6358509 ],\n",
       "       [ 0.96406096],\n",
       "       [ 0.2388387 ],\n",
       "       [ 0.7859251 ],\n",
       "       [ 0.5857236 ],\n",
       "       [ 1.0176582 ],\n",
       "       [-1.0005726 ],\n",
       "       [ 0.6575677 ],\n",
       "       [ 0.5882072 ],\n",
       "       [ 0.8060838 ],\n",
       "       [ 0.5342318 ],\n",
       "       [-0.5358603 ],\n",
       "       [-0.32548565],\n",
       "       [-0.03846804],\n",
       "       [ 0.64428663],\n",
       "       [-0.9381095 ],\n",
       "       [-1.0902832 ],\n",
       "       [ 0.35610735],\n",
       "       [-0.7621043 ],\n",
       "       [ 0.11275433],\n",
       "       [ 0.6530969 ],\n",
       "       [ 0.61683947],\n",
       "       [ 0.7420131 ],\n",
       "       [-0.4589457 ],\n",
       "       [ 0.7146081 ],\n",
       "       [ 0.4189333 ],\n",
       "       [ 0.2573559 ],\n",
       "       [ 0.9799189 ],\n",
       "       [ 0.8599703 ],\n",
       "       [ 0.62944055],\n",
       "       [ 0.88174456],\n",
       "       [ 0.10405748],\n",
       "       [ 0.83548886],\n",
       "       [ 0.552561  ],\n",
       "       [ 0.9724212 ],\n",
       "       [ 0.59606266],\n",
       "       [-1.0840932 ],\n",
       "       [-1.1266915 ],\n",
       "       [ 0.9531171 ],\n",
       "       [ 0.86411506],\n",
       "       [ 0.91291696],\n",
       "       [-0.96340257],\n",
       "       [ 0.9211991 ],\n",
       "       [ 0.6976878 ],\n",
       "       [-0.49863863],\n",
       "       [ 0.68349427],\n",
       "       [ 0.6632403 ],\n",
       "       [-0.9792513 ],\n",
       "       [ 0.9415184 ],\n",
       "       [-0.35548055],\n",
       "       [ 0.75214463],\n",
       "       [-0.7505236 ],\n",
       "       [ 0.80742514],\n",
       "       [ 0.87515914],\n",
       "       [ 0.6347944 ],\n",
       "       [ 0.37288654],\n",
       "       [ 0.74529755],\n",
       "       [ 0.8295106 ],\n",
       "       [ 0.05134223],\n",
       "       [ 0.70175415],\n",
       "       [-0.4080636 ],\n",
       "       [-0.6855971 ],\n",
       "       [ 0.8435753 ],\n",
       "       [ 0.08097516],\n",
       "       [ 0.35120127],\n",
       "       [ 0.6480157 ],\n",
       "       [ 0.88835007],\n",
       "       [-0.7108014 ],\n",
       "       [-0.03049329],\n",
       "       [ 0.959193  ],\n",
       "       [-1.11534   ],\n",
       "       [-0.8226985 ],\n",
       "       [ 0.96537125],\n",
       "       [-0.29740146],\n",
       "       [-0.31806237],\n",
       "       [ 0.5572569 ],\n",
       "       [-0.99342686],\n",
       "       [ 0.48564136],\n",
       "       [-0.9814903 ],\n",
       "       [ 0.46289426],\n",
       "       [ 0.808368  ],\n",
       "       [-0.26603824],\n",
       "       [ 0.76949525],\n",
       "       [-0.21935797],\n",
       "       [ 0.68610126],\n",
       "       [-0.5343591 ],\n",
       "       [ 0.70885956],\n",
       "       [ 0.39740494],\n",
       "       [-0.6759282 ],\n",
       "       [ 0.7919376 ],\n",
       "       [ 0.5595805 ],\n",
       "       [ 0.8676359 ],\n",
       "       [ 0.9628311 ],\n",
       "       [ 0.6837107 ],\n",
       "       [ 0.9636173 ],\n",
       "       [-1.0272326 ],\n",
       "       [-0.87602323],\n",
       "       [-0.8707021 ],\n",
       "       [ 0.91425693],\n",
       "       [ 0.41409975],\n",
       "       [ 0.7699366 ],\n",
       "       [ 0.73204184],\n",
       "       [ 1.0183611 ],\n",
       "       [-1.1673611 ],\n",
       "       [ 0.8016828 ],\n",
       "       [ 0.9936695 ],\n",
       "       [-0.81298447],\n",
       "       [ 0.39795598],\n",
       "       [-0.1890099 ],\n",
       "       [-0.1422665 ],\n",
       "       [ 0.5733089 ],\n",
       "       [ 0.68801993],\n",
       "       [ 0.53123415],\n",
       "       [ 0.53425187],\n",
       "       [ 0.5160915 ],\n",
       "       [ 0.901113  ],\n",
       "       [ 0.43478167],\n",
       "       [ 0.63168734],\n",
       "       [ 0.6961015 ],\n",
       "       [ 0.14701422],\n",
       "       [ 0.16835181],\n",
       "       [ 0.9877189 ],\n",
       "       [-0.07499446],\n",
       "       [ 0.7256119 ],\n",
       "       [ 0.93594134],\n",
       "       [-1.0191065 ],\n",
       "       [ 0.98871475],\n",
       "       [ 0.40096804],\n",
       "       [ 0.5605238 ],\n",
       "       [-0.06437685],\n",
       "       [-0.5819157 ],\n",
       "       [ 0.53505397],\n",
       "       [ 0.9868881 ],\n",
       "       [-0.9661394 ],\n",
       "       [-0.00940083],\n",
       "       [ 0.7012192 ],\n",
       "       [ 0.54847467],\n",
       "       [ 0.87459   ],\n",
       "       [ 0.64534634],\n",
       "       [ 0.6544233 ],\n",
       "       [ 0.35988912],\n",
       "       [ 0.7811703 ],\n",
       "       [ 0.8007647 ],\n",
       "       [ 0.96948403],\n",
       "       [ 0.64972067],\n",
       "       [ 0.9965383 ],\n",
       "       [ 0.93686044],\n",
       "       [ 0.5609198 ],\n",
       "       [ 0.8405186 ],\n",
       "       [ 0.98056895],\n",
       "       [ 0.99945873],\n",
       "       [ 0.78735185],\n",
       "       [-0.8045453 ],\n",
       "       [ 0.7398699 ],\n",
       "       [ 0.76711684],\n",
       "       [-0.36749014],\n",
       "       [ 0.45043886],\n",
       "       [ 0.7784179 ],\n",
       "       [-0.61795366],\n",
       "       [ 0.2978395 ],\n",
       "       [-0.74021775],\n",
       "       [ 0.8911329 ],\n",
       "       [ 1.0740707 ],\n",
       "       [-0.7667915 ],\n",
       "       [-0.12814549],\n",
       "       [-0.5643475 ],\n",
       "       [ 0.9650247 ],\n",
       "       [ 0.51069593],\n",
       "       [ 0.6347963 ],\n",
       "       [ 0.04294235],\n",
       "       [ 0.74396753],\n",
       "       [ 0.8607287 ],\n",
       "       [-0.44214535],\n",
       "       [ 0.7681349 ],\n",
       "       [ 0.44098276],\n",
       "       [-0.67248505],\n",
       "       [ 0.6741016 ],\n",
       "       [-0.35102978],\n",
       "       [ 0.6515548 ],\n",
       "       [-0.359463  ],\n",
       "       [ 0.4123771 ],\n",
       "       [ 0.43609983],\n",
       "       [-0.8846995 ],\n",
       "       [ 0.95527035],\n",
       "       [-1.04548   ],\n",
       "       [ 0.31587487],\n",
       "       [-0.5919551 ],\n",
       "       [-1.1316633 ],\n",
       "       [ 0.53291035],\n",
       "       [-1.2324655 ],\n",
       "       [-1.0192386 ],\n",
       "       [ 0.00866626],\n",
       "       [ 0.3890911 ],\n",
       "       [-1.1271185 ],\n",
       "       [ 0.36435065],\n",
       "       [ 0.68205255],\n",
       "       [ 0.04908774],\n",
       "       [ 0.53909093],\n",
       "       [-0.9893804 ],\n",
       "       [ 0.6504585 ],\n",
       "       [-0.3794746 ],\n",
       "       [-0.02919754],\n",
       "       [-1.0503762 ],\n",
       "       [-0.5491388 ],\n",
       "       [ 0.5547407 ],\n",
       "       [-1.0014511 ],\n",
       "       [ 0.82355195],\n",
       "       [ 0.2643121 ],\n",
       "       [-0.5637021 ],\n",
       "       [-0.71260524],\n",
       "       [-0.9064764 ],\n",
       "       [ 0.4722597 ],\n",
       "       [ 0.14549375],\n",
       "       [ 0.8011843 ],\n",
       "       [ 0.8125882 ],\n",
       "       [ 0.9227955 ],\n",
       "       [ 0.81747335],\n",
       "       [ 0.89791083],\n",
       "       [ 0.7616793 ],\n",
       "       [-0.16138814],\n",
       "       [ 0.8287833 ],\n",
       "       [ 0.95118874],\n",
       "       [ 0.6207799 ],\n",
       "       [-0.5822238 ],\n",
       "       [ 0.7160951 ],\n",
       "       [-0.8736437 ],\n",
       "       [ 0.53691983],\n",
       "       [ 0.7189865 ],\n",
       "       [-0.9385346 ],\n",
       "       [ 0.0500275 ],\n",
       "       [-0.87557656]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = pickle.load(open('fitted-model.pkl','rb'))\n",
    "pipeline.predict(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sigopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.9186\u001b[0m        \u001b[32m0.7733\u001b[0m     +  0.6957\n",
      "      2        \u001b[36m0.6103\u001b[0m        \u001b[32m0.5523\u001b[0m     +  0.6514\n",
      "      3        0.6175        \u001b[32m0.4866\u001b[0m     +  0.6517\n",
      "      4        \u001b[36m0.5823\u001b[0m        0.5521        0.6505\n",
      "      5        \u001b[36m0.5634\u001b[0m        0.5235        0.6507\n",
      "      6        \u001b[36m0.4783\u001b[0m        \u001b[32m0.4176\u001b[0m     +  0.6510\n",
      "      7        \u001b[36m0.4322\u001b[0m        0.5811        0.6509\n",
      "      8        0.4400        0.5440        0.6510\n",
      "      9        \u001b[36m0.3997\u001b[0m        0.5409        0.6506\n",
      "     10        0.4102        0.4641        0.6516\n",
      "     11        \u001b[36m0.3914\u001b[0m        0.4689        0.6505\n",
      "     12        \u001b[36m0.3908\u001b[0m        0.4374        0.6507\n",
      "     13        \u001b[36m0.3846\u001b[0m        0.4354        0.6509\n",
      "     14        \u001b[36m0.3839\u001b[0m        \u001b[32m0.4175\u001b[0m     +  0.6510\n",
      "     15        \u001b[36m0.3720\u001b[0m        0.4248        0.6522\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7934\u001b[0m        \u001b[32m0.5754\u001b[0m     +  0.6515\n",
      "      2        \u001b[36m0.6156\u001b[0m        0.5977        0.6494\n",
      "      3        0.6446        \u001b[32m0.5240\u001b[0m     +  0.6519\n",
      "      4        \u001b[36m0.5919\u001b[0m        0.5630        0.6525\n",
      "      5        0.6021        0.5339        0.6526\n",
      "      6        \u001b[36m0.5481\u001b[0m        \u001b[32m0.4444\u001b[0m     +  0.6524\n",
      "      7        \u001b[36m0.4634\u001b[0m        \u001b[32m0.4357\u001b[0m     +  0.6526\n",
      "      8        \u001b[36m0.4316\u001b[0m        0.6546        0.6524\n",
      "      9        0.4415        0.5433        0.6515\n",
      "     10        \u001b[36m0.4116\u001b[0m        0.5035        0.6534\n",
      "     11        \u001b[36m0.4096\u001b[0m        0.4431        0.6519\n",
      "     12        \u001b[36m0.4094\u001b[0m        \u001b[32m0.3832\u001b[0m     +  0.6520\n",
      "     13        \u001b[36m0.3927\u001b[0m        \u001b[32m0.3592\u001b[0m     +  0.6525\n",
      "     14        0.4056        \u001b[32m0.3479\u001b[0m     +  0.6538\n",
      "     15        \u001b[36m0.3882\u001b[0m        0.3526        0.6547\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8587\u001b[0m        \u001b[32m0.5850\u001b[0m     +  0.6571\n",
      "      2        \u001b[36m0.6107\u001b[0m        \u001b[32m0.5812\u001b[0m     +  0.6558\n",
      "      3        0.6491        \u001b[32m0.5246\u001b[0m     +  0.6555\n",
      "      4        \u001b[36m0.6022\u001b[0m        0.5542        0.6556\n",
      "      5        0.6084        0.5493        0.6560\n",
      "      6        \u001b[36m0.5736\u001b[0m        \u001b[32m0.5006\u001b[0m     +  0.6564\n",
      "      7        \u001b[36m0.5382\u001b[0m        \u001b[32m0.4389\u001b[0m     +  0.6554\n",
      "      8        \u001b[36m0.4774\u001b[0m        0.4505        0.6565\n",
      "      9        \u001b[36m0.4370\u001b[0m        0.8436        0.6536\n",
      "     10        0.4515        0.4502        0.6536\n",
      "     11        \u001b[36m0.4309\u001b[0m        \u001b[32m0.3979\u001b[0m     +  0.6539\n",
      "     12        \u001b[36m0.4185\u001b[0m        0.3981        0.6535\n",
      "     13        \u001b[36m0.4138\u001b[0m        \u001b[32m0.3865\u001b[0m     +  0.6538\n",
      "     14        \u001b[36m0.4003\u001b[0m        \u001b[32m0.3858\u001b[0m     +  0.6541\n",
      "     15        0.4006        \u001b[32m0.3846\u001b[0m     +  0.6538\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8977\u001b[0m        \u001b[32m0.5280\u001b[0m     +  0.6535\n",
      "      2        \u001b[36m0.6449\u001b[0m        0.5979        0.6512\n",
      "      3        \u001b[36m0.5870\u001b[0m        0.5524        0.6516\n",
      "      4        \u001b[36m0.5840\u001b[0m        0.6055        0.6514\n",
      "      5        0.5896        0.5557        0.6511\n",
      "      6        \u001b[36m0.5507\u001b[0m        \u001b[32m0.5253\u001b[0m     +  0.6513\n",
      "      7        \u001b[36m0.5462\u001b[0m        0.5286        0.6514\n",
      "      8        0.5533        \u001b[32m0.5154\u001b[0m     +  0.6520\n",
      "      9        \u001b[36m0.5285\u001b[0m        \u001b[32m0.4913\u001b[0m     +  0.6511\n",
      "     10        \u001b[36m0.4788\u001b[0m        1.1906        0.6543\n",
      "     11        \u001b[36m0.4175\u001b[0m        \u001b[32m0.4399\u001b[0m     +  0.6536\n",
      "     12        \u001b[36m0.3822\u001b[0m        0.5618        0.6539\n",
      "     13        0.3864        \u001b[32m0.4124\u001b[0m     +  0.6546\n",
      "     14        0.3830        \u001b[32m0.3918\u001b[0m     +  0.6541\n",
      "     15        \u001b[36m0.3627\u001b[0m        0.5562        0.6551\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8886\u001b[0m        \u001b[32m0.5468\u001b[0m     +  0.6564\n",
      "      2        \u001b[36m0.6953\u001b[0m        0.5605        0.6574\n",
      "      3        \u001b[36m0.6018\u001b[0m        0.5649        0.6553\n",
      "      4        0.6208        0.5923        0.6558\n",
      "      5        0.6076        \u001b[32m0.5376\u001b[0m     +  0.6555\n",
      "      6        \u001b[36m0.5779\u001b[0m        \u001b[32m0.5250\u001b[0m     +  0.6556\n",
      "      7        0.5887        0.5253        0.6558\n",
      "      8        0.5828        0.5284        0.6556\n",
      "      9        0.5781        0.5375        0.6559\n",
      "     10        0.5825        0.5361        0.6559\n",
      "     11        0.5783        0.5282        0.6561\n",
      "     12        \u001b[36m0.5770\u001b[0m        \u001b[32m0.5247\u001b[0m     +  0.6557\n",
      "     13        0.5780        \u001b[32m0.5244\u001b[0m     +  0.6560\n",
      "     14        \u001b[36m0.5743\u001b[0m        0.5255        0.6555\n",
      "     15        \u001b[36m0.5677\u001b[0m        \u001b[32m0.5154\u001b[0m     +  0.6552\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8252\u001b[0m        \u001b[32m0.5108\u001b[0m     +  0.6968\n",
      "      2        \u001b[36m0.6229\u001b[0m        0.6279        0.6552\n",
      "      3        0.6406        \u001b[32m0.4868\u001b[0m     +  0.6549\n",
      "      4        \u001b[36m0.5971\u001b[0m        0.5480        0.6550\n",
      "      5        0.6098        0.5047        0.6551\n",
      "      6        \u001b[36m0.5774\u001b[0m        \u001b[32m0.4667\u001b[0m     +  0.6605\n",
      "      7        \u001b[36m0.5595\u001b[0m        \u001b[32m0.4495\u001b[0m     +  0.6556\n",
      "      8        \u001b[36m0.4855\u001b[0m        \u001b[32m0.4318\u001b[0m     +  0.6550\n",
      "      9        \u001b[36m0.4377\u001b[0m        0.6167        0.6544\n",
      "     10        \u001b[36m0.4321\u001b[0m        0.5221        0.6552\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8630\u001b[0m        \u001b[32m0.6370\u001b[0m     +  0.6543\n",
      "      2        \u001b[36m0.6164\u001b[0m        \u001b[32m0.5786\u001b[0m     +  0.6553\n",
      "      3        0.6464        \u001b[32m0.5408\u001b[0m     +  0.6557\n",
      "      4        \u001b[36m0.5976\u001b[0m        \u001b[32m0.5406\u001b[0m     +  0.6546\n",
      "      5        0.5986        0.5443        0.6540\n",
      "      6        \u001b[36m0.5717\u001b[0m        \u001b[32m0.5025\u001b[0m     +  0.6551\n",
      "      7        \u001b[36m0.5293\u001b[0m        \u001b[32m0.4399\u001b[0m     +  0.6555\n",
      "      8        \u001b[36m0.4550\u001b[0m        \u001b[32m0.4127\u001b[0m     +  0.6552\n",
      "      9        \u001b[36m0.4249\u001b[0m        0.6266        0.6566\n",
      "     10        0.4264        0.5129        0.6563\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8405\u001b[0m        \u001b[32m0.7678\u001b[0m     +  0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6122\u001b[0m        \u001b[32m0.5466\u001b[0m     +  0.6563\n",
      "      3        0.6262        \u001b[32m0.5233\u001b[0m     +  0.6554\n",
      "      4        \u001b[36m0.5973\u001b[0m        0.5484        0.6556\n",
      "      5        \u001b[36m0.5839\u001b[0m        0.5620        0.6560\n",
      "      6        \u001b[36m0.5293\u001b[0m        0.5474        0.6555\n",
      "      7        \u001b[36m0.4597\u001b[0m        \u001b[32m0.3963\u001b[0m     +  0.6547\n",
      "      8        \u001b[36m0.4450\u001b[0m        0.5688        0.6562\n",
      "      9        \u001b[36m0.4406\u001b[0m        0.5484        0.6553\n",
      "     10        \u001b[36m0.4196\u001b[0m        0.4945        0.6558\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8385\u001b[0m        \u001b[32m0.6565\u001b[0m     +  0.6522\n",
      "      2        \u001b[36m0.5561\u001b[0m        \u001b[32m0.5863\u001b[0m     +  0.6509\n",
      "      3        0.6007        \u001b[32m0.5263\u001b[0m     +  0.6506\n",
      "      4        \u001b[36m0.5508\u001b[0m        0.5618        0.6514\n",
      "      5        0.5625        0.5588        0.6509\n",
      "      6        \u001b[36m0.5361\u001b[0m        \u001b[32m0.5189\u001b[0m     +  0.6504\n",
      "      7        \u001b[36m0.5142\u001b[0m        \u001b[32m0.5058\u001b[0m     +  0.6510\n",
      "      8        \u001b[36m0.4982\u001b[0m        \u001b[32m0.4833\u001b[0m     +  0.6512\n",
      "      9        \u001b[36m0.4567\u001b[0m        \u001b[32m0.4590\u001b[0m     +  0.6510\n",
      "     10        \u001b[36m0.3932\u001b[0m        0.9451        0.6512\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8923\u001b[0m        \u001b[32m0.5531\u001b[0m     +  0.6552\n",
      "      2        \u001b[36m0.6345\u001b[0m        0.6054        0.6556\n",
      "      3        0.6365        \u001b[32m0.5333\u001b[0m     +  0.6574\n",
      "      4        \u001b[36m0.5964\u001b[0m        0.5931        0.6562\n",
      "      5        0.6077        0.5517        0.6560\n",
      "      6        \u001b[36m0.5580\u001b[0m        \u001b[32m0.4913\u001b[0m     +  0.6569\n",
      "      7        \u001b[36m0.4989\u001b[0m        \u001b[32m0.4384\u001b[0m     +  0.6575\n",
      "      8        \u001b[36m0.4487\u001b[0m        0.4622        0.6565\n",
      "      9        \u001b[36m0.4280\u001b[0m        0.5451        0.6562\n",
      "     10        \u001b[36m0.4172\u001b[0m        0.5236        0.6562\n",
      "Re-initializing module because the following parameters were re-set: atom_fea_len, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7704\u001b[0m        \u001b[32m0.5799\u001b[0m     +  0.8152\n",
      "      2        \u001b[36m0.6430\u001b[0m        \u001b[32m0.5409\u001b[0m     +  0.8162\n",
      "      3        \u001b[36m0.5887\u001b[0m        0.5838        0.8176\n",
      "      4        0.5910        \u001b[32m0.5392\u001b[0m     +  0.8189\n",
      "      5        \u001b[36m0.5520\u001b[0m        \u001b[32m0.4860\u001b[0m     +  0.8178\n",
      "      6        \u001b[36m0.4658\u001b[0m        \u001b[32m0.4646\u001b[0m     +  0.8179\n",
      "      7        \u001b[36m0.4107\u001b[0m        \u001b[32m0.4601\u001b[0m     +  0.8181\n",
      "      8        0.4183        \u001b[32m0.4007\u001b[0m     +  0.8181\n",
      "      9        \u001b[36m0.4103\u001b[0m        0.4065        0.8182\n",
      "     10        \u001b[36m0.4036\u001b[0m        0.4019        0.8177\n",
      "     11        \u001b[36m0.3940\u001b[0m        \u001b[32m0.3710\u001b[0m     +  0.8185\n",
      "     12        \u001b[36m0.3883\u001b[0m        \u001b[32m0.3681\u001b[0m     +  0.8185\n",
      "     13        \u001b[36m0.3848\u001b[0m        \u001b[32m0.3655\u001b[0m     +  0.8198\n",
      "     14        \u001b[36m0.3720\u001b[0m        0.3670        0.8202\n",
      "     15        0.3749        \u001b[32m0.3649\u001b[0m     +  0.8197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SigOptSearchCV(client_token=None, cv=5, cv_timeout=None, error_score='raise',\n",
       "        estimator=<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=CrystalGraphConvNet(\n",
       "    (embedding): Linear(in_features=94, out_features=46, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0): ConvLayer(\n",
       "        (fc_full): Linear(in_features=98, out_features=92, bias=True)\n",
       "        (sigmo...s(beta=1, threshold=20)\n",
       "    )\n",
       "    (fc_out): Linear(in_features=83, out_features=1, bias=True)\n",
       "  ),\n",
       "),\n",
       "        fit_params=None, iid=True, n_iter=2, n_jobs=1, n_sug=1,\n",
       "        opt_timeout=None, param_domains={'max_epochs': (10, 20)},\n",
       "        pre_dispatch='2*n_jobs', refit=True,\n",
       "        scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "        sigopt_connection=<sigopt.interface.Connection object at 0x7fe600305f28>,\n",
       "        verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sigopt_sklearn.search import SigOptSearchCV\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "client_token = 'insert_sigopt_token_here'\n",
    "\n",
    "net_parameters  = {'max_epochs': (10,20)}\n",
    "\n",
    "clf = SigOptSearchCV(net, net_parameters, cv=5,\n",
    "    client_token=client_token, n_jobs=1, n_iter=2, scoring=get_scorer('neg_mean_absolute_error'))\n",
    "\n",
    "clf.fit(SDT_list, target_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
